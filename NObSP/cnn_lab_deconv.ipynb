{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader as tf_dataloader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device=mps_device)\n",
    "    print (x)\n",
    "else:\n",
    "    print (\"MPS device not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]\n",
    ")\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(\n",
    "    root=\"./data\", train=True, download=True, transform=transform\n",
    ")\n",
    "trainloader = tf_dataloader(\n",
    "    trainset, batch_size=batch_size, shuffle=True, num_workers=2\n",
    ")\n",
    "\n",
    "testset = torchvision.datasets.MNIST(\n",
    "    root=\"./data\", train=False, download=True, transform=transform\n",
    ")\n",
    "testloader = tf_dataloader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = tuple(str(i) for i in range(10))  # MNIST classes are digits from 0 to 9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5    \n"
     ]
    }
   ],
   "source": [
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(\" \".join(f\"{classes[labels[j]]:5s}\" for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=3, return_indices=True),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=3, return_indices=True),\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(in_features=256, out_features=128),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(in_features=128, out_features=10),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        \n",
    "        self.conv_layers_indices = [0, 2]\n",
    "        \n",
    "        self.feature_maps = OrderedDict()\n",
    "        \n",
    "        self.pool_locs = OrderedDict()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for idx, layer in enumerate(self.features):\n",
    "            if isinstance(layer, nn.MaxPool2d):\n",
    "                x, location = layer(x)\n",
    "                self.pool_locs[idx] = location\n",
    "            else:\n",
    "                x = layer(x)\n",
    "                \n",
    "        output = self.classifier(x)\n",
    "        return output\n",
    "                    \n",
    "net = Net()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.layer2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.layer3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.layer4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.layer5 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.layer6 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.layer7 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
    "        self.layer8 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.layer9 = nn.Flatten()\n",
    "        self.drop1 = nn.Dropout(p=0.2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=256, out_features=128)\n",
    "        self.drop2 = nn.Dropout(p=0.2)\n",
    "        self.fc2 = nn.Linear(in_features=128, out_features=64)\n",
    "        self.drop3 = nn.Dropout(p=0.2)\n",
    "        self.fc3 = nn.Linear(in_features=64, out_features=10) \n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x1 = self.layer1(x)\n",
    "        self.x2 = F.relu(self.layer2(self.x1))\n",
    "        self.x3 = self.layer3(self.x2)\n",
    "        self.x4 = F.relu(self.layer4(self.x3))\n",
    "        self.x5 = self.layer5(self.x4)\n",
    "        self.x6 = F.relu(self.layer6(self.x5))\n",
    "        self.x7 = self.layer7(self.x6)\n",
    "        self.x8 = F.relu(self.layer8(self.x7))\n",
    "        self.x9 = self.layer9(self.x8)\n",
    "        self.x10 = self.drop1(self.x9)\n",
    "        \n",
    "        self.x11 = F.relu(self.fc1(self.x10))\n",
    "        self.x12 = self.drop2(self.x11)\n",
    "        self.x13 = F.relu(self.fc2(self.x12))\n",
    "        self.x14 = self.drop3(self.x13)\n",
    "        self.x15 = F.softmax(self.fc3(self.x14), dim = 1)\n",
    "            \n",
    "        return self.x15\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  1000] loss: 1.091\n",
      "[1,  2000] loss: 0.934\n",
      "[1,  3000] loss: 0.868\n",
      "[1,  4000] loss: 0.840\n",
      "[1,  5000] loss: 0.821\n",
      "[1,  6000] loss: 0.796\n",
      "[1,  7000] loss: 0.788\n",
      "[1,  8000] loss: 0.789\n",
      "[1,  9000] loss: 0.780\n",
      "[1, 10000] loss: 0.772\n",
      "[1, 11000] loss: 0.772\n",
      "[1, 12000] loss: 0.779\n",
      "[1, 13000] loss: 0.776\n",
      "[1, 14000] loss: 0.765\n",
      "[1, 15000] loss: 0.763\n",
      "[1, 16000] loss: 0.771\n",
      "[1, 17000] loss: 0.764\n",
      "[1, 18000] loss: 0.766\n",
      "[1, 19000] loss: 0.763\n",
      "[1, 20000] loss: 0.761\n",
      "[1, 21000] loss: 0.764\n",
      "[1, 22000] loss: 0.762\n",
      "[1, 23000] loss: 0.761\n",
      "[1, 24000] loss: 0.761\n",
      "[1, 25000] loss: 0.756\n",
      "[1, 26000] loss: 0.763\n",
      "[1, 27000] loss: 0.755\n",
      "[1, 28000] loss: 0.759\n",
      "[1, 29000] loss: 0.761\n",
      "[1, 30000] loss: 0.762\n",
      "[1, 31000] loss: 0.761\n",
      "[1, 32000] loss: 0.758\n",
      "[1, 33000] loss: 0.751\n",
      "[1, 34000] loss: 0.761\n",
      "[1, 35000] loss: 0.758\n",
      "[1, 36000] loss: 0.756\n",
      "[1, 37000] loss: 0.755\n",
      "[1, 38000] loss: 0.757\n",
      "[1, 39000] loss: 0.752\n",
      "[1, 40000] loss: 0.757\n",
      "[1, 41000] loss: 0.749\n",
      "[1, 42000] loss: 0.751\n",
      "[1, 43000] loss: 0.752\n",
      "[1, 44000] loss: 0.750\n",
      "[1, 45000] loss: 0.751\n",
      "[1, 46000] loss: 0.752\n",
      "[1, 47000] loss: 0.752\n",
      "[1, 48000] loss: 0.751\n",
      "[1, 49000] loss: 0.754\n",
      "[1, 50000] loss: 0.757\n",
      "[1, 51000] loss: 0.756\n",
      "[1, 52000] loss: 0.758\n",
      "[1, 53000] loss: 0.751\n",
      "[1, 54000] loss: 0.750\n",
      "[1, 55000] loss: 0.754\n",
      "[1, 56000] loss: 0.747\n",
      "[1, 57000] loss: 0.751\n",
      "[1, 58000] loss: 0.747\n",
      "[1, 59000] loss: 0.749\n",
      "[1, 60000] loss: 0.752\n",
      "Test Loss: 1.4887632266879083\n",
      "[2,  1000] loss: 0.744\n",
      "[2,  2000] loss: 0.748\n",
      "[2,  3000] loss: 0.749\n",
      "[2,  4000] loss: 0.745\n",
      "[2,  5000] loss: 0.749\n",
      "[2,  6000] loss: 0.748\n",
      "[2,  7000] loss: 0.742\n",
      "[2,  8000] loss: 0.745\n",
      "[2,  9000] loss: 0.746\n",
      "[2, 10000] loss: 0.746\n",
      "[2, 11000] loss: 0.743\n",
      "[2, 12000] loss: 0.748\n",
      "[2, 13000] loss: 0.744\n",
      "[2, 14000] loss: 0.745\n",
      "[2, 15000] loss: 0.747\n",
      "[2, 16000] loss: 0.746\n",
      "[2, 17000] loss: 0.745\n",
      "[2, 18000] loss: 0.745\n",
      "[2, 19000] loss: 0.746\n",
      "[2, 20000] loss: 0.744\n",
      "[2, 21000] loss: 0.747\n",
      "[2, 22000] loss: 0.742\n",
      "[2, 23000] loss: 0.747\n",
      "[2, 24000] loss: 0.744\n",
      "[2, 25000] loss: 0.744\n",
      "[2, 26000] loss: 0.741\n",
      "[2, 27000] loss: 0.741\n",
      "[2, 28000] loss: 0.742\n",
      "[2, 29000] loss: 0.743\n",
      "[2, 30000] loss: 0.747\n",
      "[2, 31000] loss: 0.748\n",
      "[2, 32000] loss: 0.743\n",
      "[2, 33000] loss: 0.744\n",
      "[2, 34000] loss: 0.744\n",
      "[2, 35000] loss: 0.741\n",
      "[2, 36000] loss: 0.743\n",
      "[2, 37000] loss: 0.745\n",
      "[2, 38000] loss: 0.747\n",
      "[2, 39000] loss: 0.742\n",
      "[2, 40000] loss: 0.743\n",
      "[2, 41000] loss: 0.742\n",
      "[2, 42000] loss: 0.740\n",
      "[2, 43000] loss: 0.737\n",
      "[2, 44000] loss: 0.743\n",
      "[2, 45000] loss: 0.745\n",
      "[2, 46000] loss: 0.742\n",
      "[2, 47000] loss: 0.744\n",
      "[2, 48000] loss: 0.746\n",
      "[2, 49000] loss: 0.743\n",
      "[2, 50000] loss: 0.745\n",
      "[2, 51000] loss: 0.741\n",
      "[2, 52000] loss: 0.740\n",
      "[2, 53000] loss: 0.743\n",
      "[2, 54000] loss: 0.745\n",
      "[2, 55000] loss: 0.745\n",
      "[2, 56000] loss: 0.746\n",
      "[2, 57000] loss: 0.739\n",
      "[2, 58000] loss: 0.742\n",
      "[2, 59000] loss: 0.742\n",
      "[2, 60000] loss: 0.741\n",
      "Test Loss: 1.4829414487719537\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "patience = 2  # Define the number of epochs to tolerate before early stopping\n",
    "best_loss = float('inf')\n",
    "counter = 0\n",
    "\n",
    "y = []\n",
    "images = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    output_tensors = []\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        \n",
    "        if epoch == epochs-1:\n",
    "            images.append(inputs)\n",
    "            y.append(labels)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:  # print every 1000 mini-batches\n",
    "            print(f\"[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}\")\n",
    "            running_loss = 0.0\n",
    "    \n",
    "    # Calculate test loss\n",
    "    test_loss = 0.0\n",
    "    net.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloader:\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "    \n",
    "    # Print test loss for the epoch\n",
    "    print(f\"Test Loss: {test_loss / len(testloader)}\")\n",
    "    \n",
    "    # Check for early stopping\n",
    "    if test_loss < best_loss:\n",
    "        best_loss = test_loss\n",
    "        counter = 0\n",
    "        # Save the best model\n",
    "        torch.save(net.state_dict(), 'best_model.pth')\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            images.append(inputs)\n",
    "            y.append(labels)\n",
    "            print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "            break\n",
    "    \n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 97.86 %\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the trained model on test data\n",
    "net.load_state_dict(torch.load('best_model.pth'))\n",
    "net.eval()  # Set model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(testloader, 0):\n",
    "        images, labels = data\n",
    "\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Test Accuracy: {accuracy:.2f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'net_deconv.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
