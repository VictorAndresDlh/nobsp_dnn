{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from torchvision.models import SqueezeNet1_1_Weights, ResNet18_Weights, DenseNet161_Weights\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader as tf_dataloader\n",
    "import numpy as np\n",
    "import cv2\n",
    "import json\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    #transforms.Resize(256),\n",
    "    #transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "# Train data\n",
    "mnist = torchvision.datasets.MNIST(\n",
    "    root=\"./data\", train=True, download=True, transform=transform\n",
    ")\n",
    "dataloader = tf_dataloader(\n",
    "    mnist, batch_size=batch_size, shuffle=True, num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    plt.figure(figsize=(2, 2))\n",
    "    img = img / 2 + 0.5  # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAK4AAACuCAYAAACvDDbuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEc0lEQVR4nO3dPUtjTRxA8cliIYIRERQFX4qkELG01A9gI4hgYyMWVuIXsdXCRuwFCwtB0EJB0EYQFIPYWIkQsdJCJE/xlDOB63qTzUnOr/wzsrPhMHDvzUuhVqvVggTz519vQPobhiskwxWS4QrJcIVkuEIyXCEZrpAMV0hdWRcWCoVG7kMKIYSQ9UGuJ66QDFdIhiskwxWS4QrJcIVkuEIyXCEZrpAMV0iGKyTDFZLhCslwhWS4QjJcIRmukAxXSIYrJMMVkuEKyXCFZLhCMlwhGa6QDFdIhiskwxWS4QrJcIVkuEIyXCEZrpAMV0iGKyTDFZLhCinzr+60gsXFxWh2cHCQXLuxsRHNtre3c99TXkqlUjQbGBhIrn17e4tmj4+Pue+plXniCslwhWS4QjJcIRmukAq1jD+e2gq/5Vsul6PZw8NDcu3X11c0q1QqybVXV1fR7O7uLrl2dXU1mtV7bVLzei/32NhYNOvr60uuPTo6imYLCwvJtTT+lq/amuEKyXCFZLhCQl2cFYvFaHZ+fp5cOz093ejttJTBwcHkvFqtNnknv+PFmdqa4QrJcIVkuEIyXCGh7iqk9PT0JOfLy8vRbH19Pbn29PQ0mtX7/2a96g0hhIuLi2hW77FzSurN8CGEsLm5Gc1mZ2eTay8vLzP/e63Auwpqa4YrJMMVkuEKCX9x1s52d3eT87W1tWjmI18JwHCFZLhCMlwhGa6QUN8d1s66u7uj2fz8fHLt5+dnNPv+/s59T63ME1dIhiskwxWS4QrJi7MWMTc3F81GRkaSaw8PD6PZ+/t73ltqaZ64QjJcIRmukAxXSIYrJO8qNFnq0W4IIWxtbUWzem+qvr6+znVPRJ64QjJcIRmukAxXSF6cNdnS0lJyPjU1Fc1S77sNIYTj4+Nc90TkiSskwxWS4QrJcIVkuELyrkKTDQ0NZV779PSUnN/e3ua1HSxPXCEZrpAMV0iGKyQvzppscnIy89rUp3n1P09cIRmukAxXSIYrJMMVkj8X1UDFYjGa1Xtc29vbG83q3YF4fX393cZamD8XpbZmuEIyXCEZrpB85NtAKysr0Wx0dDS59uTkJJq180XYb3niCslwhWS4QjJcIRmukLyr0EAzMzP/egttyxNXSIYrJMMVkuEKyYuzHHR1pV/Gel/inHJzc5PXdjqCJ66QDFdIhiskwxWS4QrJT/nmoFQqJeeVSiWafXx8JNeWy+Vo9vLy8ruNAfkpX7U1wxWS4QrJcIXkI98c7O/vJ+epC9q9vb3k2k68EPsNT1whGa6QDFdIhiskwxWSdxV+qL+/P5oNDw9n/vv7+/s8t9OxPHGFZLhCMlwhGa6QvDj7oYmJiWg2Pj6e+e/Pzs5y3E3n8sQVkuEKyXCFZLhCMlwheVfhh6rVaqZZCCHs7OxEs+fn59z31Ik8cYVkuEIyXCEZrpD8Cia1FL+CSW3NcIVkuEIyXCEZrpAyP/LNerUnNYMnrpAMV0iGKyTDFZLhCslwhWS4QjJcIRmukP4D/8XNVHZ0RaUAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get some random training images\n",
    "dataiter = iter(dataloader)\n",
    "images, labels = next(dataiter)\n",
    "print(labels)\n",
    "imshow(torchvision.utils.make_grid(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layer1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.layer2 = nn.MaxPool2d(kernel_size=2, stride=3)\n",
    "        \n",
    "        self.layer3 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.layer4 = nn.MaxPool2d(kernel_size=2, stride=3)\n",
    "        \n",
    "        self.layer5 = nn.Flatten()\n",
    "        self.drop1 = nn.Dropout(p=0.2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=288, out_features=128)\n",
    "        self.fc2 = nn.Linear(in_features=128, out_features=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        self.x1 = self.layer1(x)\n",
    "        self.x2 = F.relu(self.layer2(self.x1))\n",
    "        \n",
    "        self.x3 = self.layer3(self.x2)\n",
    "        self.x4 = F.relu(self.layer4(self.x3))\n",
    "        \n",
    "        self.x5 = self.layer5(self.x4)\n",
    "        self.x6 = self.drop1(self.x5)\n",
    "        \n",
    "        self.x7 = F.relu(self.fc1(self.x6))\n",
    "        self.x8 = F.softmax(self.fc2(self.x7), dim = 1)\n",
    "            \n",
    "        return self.x8, self.x4\n",
    "\n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (layer1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (layer2): MaxPool2d(kernel_size=2, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "  (layer3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (layer4): MaxPool2d(kernel_size=2, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "  (layer5): Flatten(start_dim=1, end_dim=-1)\n",
       "  (drop1): Dropout(p=0.2, inplace=False)\n",
       "  (fc1): Linear(in_features=288, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating the trained model on test data\n",
    "model.load_state_dict(torch.load('best_model_mnist.pth'))\n",
    "model.eval()  # Set model to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "model.eval()  # Eval mode\n",
    "\n",
    "\n",
    "# Pasamos la imagen por el modelo.\n",
    "output, feature_maps = model(images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 3, 3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_maps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "X"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
